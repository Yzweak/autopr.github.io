\begin{table*}[t!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|cc|cccccc|cccc|c}
\toprule
\multirow{2}{*}{\textbf{Model Name}} & \multicolumn{2}{c|}{\textbf{Fidelity}} & \multicolumn{6}{c|}{\textbf{Engagement}} & \multicolumn{4}{c|}{\textbf{Alignment}} & \multirow{3}{*}{\textbf{Avg.}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-9} \cmidrule(lr){10-13}
& \begin{tabular}[c]{@{}c@{}}A\&T \\ Acc.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Factual \\ Score\end{tabular} & Hook & \begin{tabular}[c]{@{}c@{}}Logical \\ Attr.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Visual \\ Attr.\end{tabular} & CTA & \begin{tabular}[c]{@{}c@{}}Prof. \\ Pref.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Broad \\ Pref.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Context \\ Rel.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Vis-Txt \\ Integ.\end{tabular} & Hashtag & \begin{tabular}[c]{@{}c@{}}Plat. \\ Pref.\end{tabular} & \\
\midrule
DeepSeek-R1-Distill-7B$^{R,T}$ & 43.25 & 21.45 & 33.07 & 45.04 & - & 15.34 & 37.70 & 43.25 & 31.28 & - & 17.13 & 23.02 & 31.05 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 55.60 & 36.43 & 68.10 & 71.58 & 62.89 & 34.96 & 72.27 & 88.67 & 66.89 & 66.47 & 52.64 & 81.64 & 63.18 \\
\midrule
Qwen2.5-VL-7B-Ins & 49.15 & 39.17 & 62.83 & 46.60 & - & 39.19 & 34.77 & 58.59 & 55.86 & - & 40.46 & 60.16 & 48.68 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 62.17 & 57.89 & 62.57 & 58.33 & 59.32 & 15.62 & 66.41 & 74.61 & 57.40 & 60.61 & 50.26 & 70.31 & 57.96 \\
\midrule
InternVL3-8B & 52.67 & 48.55 & 72.01 & 53.09 & - & 50.00 & 63.67 & 81.64 & 66.34 & - & 56.58 & 85.16 & 62.97 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 64.06 & 52.50 & 73.37 & 57.62 & 68.75 & 44.27 & 60.55 & 88.67 & 74.93 & 66.24 & 50.68 & 80.86 & 65.21 \\
\midrule
Qwen3-8B$^{T}$ & 51.76 & 45.09 & 73.83 & 51.69 & - & 44.27 & 62.50 & 78.91 & 72.10 & - & 61.46 & 91.41 & 63.30 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.01 & 62.11 & 75.00 & 83.53 & 70.57 & 45.44 & 96.09 & 98.44 & 86.33 & 71.78 & 62.11 & 98.44 & 76.57 \\
\midrule
DeepSeek-R1-Distill-14B$^{R,T}$ & 51.37 & 43.57 & 69.14 & 54.92 & - & 29.56 & 60.16 & 75.78 & 64.23 & - & 50.13 & 81.64 & 58.05 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 66.60 & 57.21 & 74.80 & 77.64 & 73.31 & 38.48 & 91.80 & 98.83 & 80.37 & 72.66 & 54.95 & 99.22 & 73.82 \\
\midrule
InternVL3-14B & 52.41 & 49.12 & 71.29 & 54.52 & - & 55.66 & 56.64 & 80.86 & 68.52 & - & 57.06 & 88.67 & 63.48 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 64.78 & 55.91 & 75.26 & 67.06 & 73.05 & 52.80 & 73.05 & 92.19 & 80.79 & 71.55 & 53.22 & 87.89 & 70.63 \\
\midrule
Qwen3-14B$^{T}$ & 50.91 & 47.44 & 74.80 & 56.25 & - & 38.15 & 69.53 & 82.03 & 72.30 & - & 65.23 & 95.31 & 65.20 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.31 & 67.70 & 75.00 & 81.38 & 72.85 & 35.35 & 97.66 & 99.61 & 86.88 & 74.38 & 61.33 & 97.27 & 76.64 \\
\midrule
GPT-OSS-20B$^{R,T}$ & 52.30 & 56.11 & 69.34 & 40.62 & - & 44.21 & 73.44 & 74.22 & 71.52 & - & 54.88 & 90.62 & 62.73 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.12 & 75.28 & 75.00 & 64.84 & 72.46 & 47.33 & 99.22 & 98.05 & 83.59 & 73.63 & 62.76 & 99.22 & 76.79 \\
\midrule
Qwen3-30B-A3B$^{T}$ & 51.11 & 43.03 & 71.68 & 51.69 & - & 35.22 & 47.66 & 74.61 & 67.84 & - & 60.16 & 83.59 & 58.66 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.79 & 56.45 & 75.00 & 79.98 & 72.01 & 30.01 & 98.44 & 98.44 & 85.61 & 72.36 & 66.54 & 98.44 & 75.26 \\
\midrule
DeepSeek-R1-Distill-32B$^{R,T}$ & 50.00 & 42.49 & 68.03 & 55.66 & - & 35.61 & 51.95 & 77.73 & 67.25 & - & 50.46 & 85.16 & 58.43 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 65.94 & 55.82 & 72.38 & 80.22 & 69.38 & 37.80 & 92.91 & 96.06 & 79.63 & 70.51 & 47.77 & 92.52 & 71.74 \\
\midrule
Qwen2.5-VL-32B-Ins & 57.55 & 59.87 & 70.90 & 70.15 & - & 58.92 & 88.67 & 87.50 & 67.68 & - & 53.32 & 91.02 & 70.56 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 72.85 & 72.49 & 74.80 & 82.03 & 75.33 & 51.69 & 98.05 & 100.00 & 83.82 & 75.03 & 61.65 & 96.48 & 78.69 \\
\midrule
Qwen3-32B$^{T}$ & 52.73 & 52.56 & 72.98 & 54.04 & - & 47.27 & 79.30 & 80.08 & 70.41 & - & 61.98 & 92.97 & 66.43 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.31 & 64.94 & 75.00 & 83.72 & 74.61 & 42.32 & 99.22 & 100.00 & 86.91 & 75.39 & 60.71 & 99.22 & 77.70 \\
\midrule
InternVL3-38B & 51.37 & 43.82 & 71.16 & 53.91 & - & 50.07 & 44.14 & 77.73 & 68.46 & - & 50.81 & 85.94 & 59.74 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 65.69 & 56.84 & 75.00 & 72.10 & 74.02 & 47.92 & 85.55 & 96.88 & 83.66 & 74.28 & 50.91 & 96.09 & 73.25 \\
\midrule
Qwen-2.5-VL-72B-Ins & 52.08 & 44.43 & 74.41 & 62.83 & - & 57.81 & 58.20 & 83.98 & 74.67 & - & 55.53 & 93.75 & 65.77 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.05 & 60.75 & 75.00 & 75.68 & 74.93 & 30.99 & 89.45 & 97.27 & 81.32 & 74.22 & 41.60 & 96.48 & 72.31 \\
\midrule
GPT-OSS-120B$^{R,T}$ & 52.67 & 59.85 & 68.55 & 41.02 & - & 43.29 & 76.17 & 78.91 & 73.86 & - & 67.45 & 92.19 & 65.40 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.34 & 79.42 & 75.00 & 66.37 & 72.79 & 46.94 & 100.00 & 98.05 & 81.74 & 74.12 & 60.61 & 100.00 & 77.03 \\
\midrule
Qwen3-235B-A22B$^{T}$ & 55.34 & 54.28 & 74.22 & 57.29 & - & 51.82 & 80.47 & 84.38 & 74.41 & - & 69.99 & 96.09 & 69.83 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 66.80 & 66.92 & 75.33 & 83.69 & 74.87 & 42.58 & 97.66 & 100.00 & 87.17 & 75.10 & 61.13 & 97.66 & 77.41 \\
\midrule
Gemini-2.5-Flash & 55.01 & 45.10 & 74.48 & 61.78 & - & 48.96 & 39.06 & 83.98 & 80.47 & - & 61.20 & 93.75 & 64.38 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.83 & 70.01 & 75.00 & 82.32 & 74.48 & 46.81 & 97.27 & 98.83 & 85.84 & 74.80 & 57.42 & 98.05 & 77.64 \\
\midrule
Gemini-2.5-Pro$^{R}$ & 56.77 & 47.44 & 75.00 & 69.79 & - & 44.27 & 46.88 & 88.67 & 81.41 & - & 59.57 & 94.92 & 66.47 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.81 & 63.14 & 74.47 & 85.97 & 73.89 & 45.44 & 97.27 & 99.22 & 86.04 & 74.58 & 58.40 & 98.05 & 77.36 \\
\midrule
GPT-4.1 & 51.00 & 38.75 & 74.00 & 56.00 & - & 45.67 & 50.00 & 70.00 & 69.00 & - & 52.33 & 84.00 & 59.08 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.67 & 77.19 & 75.50 & 83.00 & 75.33 & 46.67 & 100.00 & 100.00 & 86.00 & 75.33 & 60.67 & 98.00 & 79.03 \\
\midrule
GPT-4o & 50.52 & 30.73 & 72.93 & 48.06 & - & 42.84 & 28.12 & 64.45 & 60.58 & - & 53.26 & 55.08 & 50.66 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 66.99 & 46.58 & 75.00 & 75.07 & 74.80 & 47.59 & 75.78 & 98.05 & 81.87 & 73.93 & 52.15 & 97.66 & 72.12 \\
\midrule
GPT-5$^{R}$ & 52.73 & 50.19 & 74.15 & 45.15 & - & 37.70 & 74.61 & 83.20 & 75.03 & - & 52.02 & 94.92 & 63.97 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 68.16 & 73.30 & 75.00 & 80.40 & 75.20 & 34.70 & 99.22 & 100.00 & 86.65 & 75.33 & 53.06 & 98.44 & 76.62 \\
\midrule
GPT-5-mini$^{R}$ & 51.37 & 61.80 & 55.27 & 38.74 & - & 31.90 & 65.23 & 61.72 & 57.71 & - & 40.30 & 79.69 & 54.37 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 72.33 & 83.61 & 74.61 & 68.07 & 74.61 & 43.49 & 99.22 & 99.61 & 81.97 & 73.83 & 52.60 & 96.48 & 76.70 \\
\midrule
GPT-5-nano$^{R}$ & 49.80 & 57.91 & 51.56 & 37.34 & - & 34.31 & 58.59 & 51.95 & 52.51 & - & 49.28 & 73.05 & 51.63 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.29 & 70.80 & 72.53 & 61.75 & 69.53 & 34.70 & 94.92 & 94.14 & 73.63 & 67.81 & 55.47 & 94.53 & 71.76 \\
\bottomrule
\end{tabular}%
}
\caption{Comprehensive main results on the PRBench-Core. For each model, we compare the performance of our \textbf{PRAgent} against the \textbf{Direct Prompt} baseline.}
\label{tab:pragent}
\end{table*}


\begin{table*}[t!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|cc|cccccc|cccc|c}
\toprule
\multirow{2}{*}{\textbf{Model Name}} & \multicolumn{2}{c|}{\textbf{Fidelity}} & \multicolumn{6}{c|}{\textbf{Engagement}} & \multicolumn{4}{c|}{\textbf{Alignment}} & \multirow{3}{*}{\textbf{Avg.}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-9} \cmidrule(lr){10-13}
& \begin{tabular}[c]{@{}c@{}}A\&T \\ Acc.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Factual \\ Score\end{tabular} & Hook & \begin{tabular}[c]{@{}c@{}}Logical \\ Attr.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Visual \\ Attr.\end{tabular} & CTA & \begin{tabular}[c]{@{}c@{}}Prof. \\ Pref.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Broad \\ Pref.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Context \\ Rel.\end{tabular} & \begin{tabular}[c]{@{}c@{}}Vis-Txt \\ Integ.\end{tabular} & Hashtag & \begin{tabular}[c]{@{}c@{}}Plat. \\ Pref.\end{tabular} & \\
\midrule
DeepSeek-R1-Distill-7B$^{R,T}$ & 43.27 & 20.39 & 36.53 & 48.30 & - & 18.87 & 40.16 & 45.57 & 33.52 & - & 20.28 & 26.38 & 33.33 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 55.75 & 32.61 & 67.94 & 70.33 & 63.96 & 33.97 & 65.62 & 87.40 & 65.81 & 66.49 & 48.62 & 81.45 & 61.66 \\
\midrule
Qwen-2.5-VL-7B-Instruct & 48.32 & 36.52 & 61.98 & 46.98 & - & 38.82 & 35.35 & 56.45 & 55.86 & - & 40.72 & 58.01 & 47.90 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 61.75 & 55.69 & 61.76 & 58.66 & 60.24 & 16.06 & 67.97 & 75.00 & 57.43 & 61.64 & 49.65 & 67.09 & 57.74 \\
\midrule
InternVL3-8B & 51.71 & 44.89 & 70.96 & 53.00 & - & 50.00 & 58.59 & 77.83 & 66.76 & - & 56.28 & 83.98 & 61.40 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 64.08 & 51.06 & 73.47 & 58.49 & 69.90 & 45.85 & 63.28 & 88.77 & 75.49 & 67.33 & 51.44 & 81.93 & 65.92 \\
\midrule
Qwen3-8B$^{T}$ & 51.16 & 42.69 & 73.26 & 52.51 & - & 41.24 & 60.64 & 76.17 & 71.40 & - & 60.61 & 89.65 & 61.93 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 67.95 & 58.96 & 75.00 & 83.53 & 71.97 & 45.30 & 97.56 & 99.22 & 86.86 & 72.74 & 61.50 & 97.95 & 76.54 \\
\midrule
DeepSeek-R1-Distill-14B$^{R,T}$ & 50.67 & 41.73 & 69.47 & 55.39 & - & 30.72 & 57.44 & 71.33 & 64.34 & - & 49.41 & 81.02 & 57.15 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 65.61 & 53.86 & 74.62 & 77.94 & 71.94 & 39.29 & 91.31 & 98.63 & 80.53 & 71.91 & 53.32 & 97.85 & 73.07 \\
\midrule
InternVL3-14B & 51.63 & 46.51 & 71.06 & 54.17 & - & 54.82 & 53.42 & 76.17 & 68.76 & - & 56.32 & 85.84 & 61.87 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 64.56 & 54.34 & 75.62 & 68.08 & 73.18 & 52.13 & 74.61 & 94.24 & 81.57 & 71.54 & 54.41 & 90.53 & 71.23 \\
\midrule
Qwen3-14B$^{T}$ & 51.12 & 46.33 & 73.73 & 56.45 & - & 39.62 & 68.46 & 80.57 & 72.34 & - & 64.78 & 92.09 & 64.55 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.58 & 65.18 & 75.00 & 82.18 & 73.88 & 34.88 & 98.93 & 99.71 & 86.83 & 74.59 & 60.90 & 98.05 & 76.64 \\
\midrule
GPT-oss-20B$^{R,T}$ & 51.71 & 54.89 & 69.97 & 41.63 & - & 44.14 & 71.48 & 72.27 & 71.77 & - & 54.51 & 90.92 & 62.33 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.74 & 73.07 & 74.85 & 64.97 & 73.04 & 49.43 & 98.44 & 97.46 & 83.47 & 73.92 & 62.24 & 97.75 & 76.53 \\
\midrule
Qwen3-30B-A3B$^{T}$ & 51.14 & 40.76 & 71.08 & 51.68 & - & 35.63 & 48.44 & 68.46 & 67.43 & - & 60.09 & 81.74 & 57.64 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.40 & 54.95 & 74.85 & 80.69 & 72.27 & 30.08 & 96.68 & 98.24 & 85.45 & 73.32 & 65.89 & 97.56 & 74.95 \\
\midrule
DeepSeek-R1-Distill-32B$^{R,T}$ & 50.52 & 41.79 & 69.16 & 57.20 & - & 36.65 & 56.64 & 73.63 & 67.16 & - & 49.63 & 85.16 & 58.75 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 65.85 & 54.88 & 74.10 & 81.44 & 70.65 & 39.53 & 92.86 & 97.26 & 81.25 & 71.58 & 49.12 & 93.64 & 72.68 \\
\midrule
Qwen-2.5-VL-32B-Instruct & 56.90 & 55.88 & 69.71 & 69.78 & - & 56.20 & 87.01 & 85.84 & 66.18 & - & 52.78 & 88.57 & 68.88 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.56 & 69.96 & 74.95 & 82.75 & 75.15 & 53.47 & 98.83 & 99.71 & 83.46 & 75.01 & 61.90 & 97.16 & 78.66 \\
\midrule
Qwen3-32B$^{T}$ & 52.25 & 49.68 & 72.51 & 53.52 & - & 47.97 & 78.22 & 77.93 & 69.60 & - & 61.21 & 90.53 & 65.34 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.14 & 64.53 & 75.00 & 83.00 & 74.82 & 42.74 & 98.83 & 99.71 & 86.69 & 75.12 & 60.59 & 98.24 & 77.53 \\
\midrule
InternVL3-38B & 50.93 & 41.47 & 70.20 & 53.52 & - & 50.07 & 48.05 & 74.22 & 67.44 & - & 51.11 & 82.91 & 58.99 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 66.52 & 53.23 & 74.56 & 72.87 & 74.10 & 48.47 & 84.47 & 96.97 & 83.11 & 73.58 & 50.75 & 96.97 & 72.97 \\
\midrule
Qwen-2.5-VL-72B-Instruct & 52.78 & 42.61 & 74.10 & 62.51 & - & 57.10 & 56.05 & 82.52 & 74.20 & - & 55.03 & 91.89 & 64.88 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 69.43 & 58.45 & 74.71 & 75.07 & 74.79 & 29.70 & 88.96 & 97.56 & 80.37 & 73.93 & 40.97 & 96.29 & 71.69 \\
\midrule
GPT-oss-120B$^{R,T}$ & 52.64 & 58.45 & 69.34 & 41.79 & - & 41.54 & 74.32 & 72.46 & 72.59 & - & 65.32 & 91.99 & 64.04 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 68.64 & 77.15 & 74.92 & 68.13 & 73.91 & 47.71 & 99.41 & 98.34 & 81.68 & 74.53 & 59.83 & 98.73 & 76.91 \\
\midrule
Qwen3-235B-A22B$^{T}$ & 56.10 & 51.28 & 74.25 & 56.88 & - & 52.20 & 78.03 & 82.81 & 74.49 & - & 68.51 & 95.21 & 68.98 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 67.95 & 66.96 & 75.02 & 83.96 & 74.53 & 44.25 & 98.63 & 99.61 & 87.09 & 75.11 & 60.45 & 98.54 & 77.68 \\
\midrule
Gemini-2.5-Flash & 54.29 & 43.20 & 74.41 & 62.07 & - & 47.05 & 38.38 & 79.98 & 80.83 & - & 61.47 & 91.80 & 63.35 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 70.43 & 67.97 & 74.53 & 82.88 & 74.41 & 46.61 & 97.46 & 98.73 & 85.32 & 74.64 & 58.30 & 96.09 & 77.28 \\
\midrule
Gemini-2.5-Pro$^{R}$ & 57.05 & 46.46 & 75.29 & 69.70 & - & 45.49 & 46.00 & 86.82 & 81.01 & - & 59.86 & 93.26 & 66.09 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 72.31 & 62.22 & 75.09 & 86.11 & 74.80 & 47.35 & 98.93 & 99.80 & 86.86 & 75.08 & 58.02 & 99.02 & 77.97 \\
\midrule
GPT-4.1 & 50.98 & 37.77 & 74.80 & 55.53 & - & 42.19 & 48.83 & 77.73 & 73.01 & - & 53.32 & 90.62 & 60.48 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 72.66 & 71.42 & 75.20 & 81.48 & 75.33 & 47.27 & 98.05 & 99.22 & 85.06 & 75.56 & 59.11 & 96.48 & 78.07 \\
\midrule
GPT-4o & 49.72 & 29.30 & 72.21 & 47.54 & - & 40.97 & 30.86 & 59.77 & 60.15 & - & 52.41 & 54.10 & 49.70 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 66.32 & 45.94 & 75.00 & 75.22 & 74.89 & 49.07 & 77.93 & 98.24 & 81.83 & 74.17 & 52.08 & 97.66 & 72.36 \\
\midrule
GPT-5$^{R}$ & 51.71 & 47.84 & 74.06 & 45.75 & - & 37.68 & 72.75 & 78.81 & 75.00 & - & 50.57 & 94.34 & 62.85 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 67.90 & 72.07 & 75.00 & 80.43 & 75.28 & 34.82 & 98.73 & 99.51 & 86.63 & 75.66 & 52.47 & 98.05 & 76.38 \\
\midrule
GPT-5-mini$^{R}$ & 50.83 & 60.16 & 55.73 & 39.41 & - & 33.30 & 64.55 & 59.08 & 58.70 & - & 39.44 & 79.20 & 54.04 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.39 & 82.35 & 74.58 & 68.52 & 73.96 & 42.85 & 99.22 & 98.24 & 82.31 & 73.58 & 52.19 & 95.90 & 76.26 \\
\midrule
GPT-5-nano$^{R}$ & 49.43 & 56.91 & 51.94 & 37.08 & - & 31.43 & 57.13 & 50.29 & 52.65 & - & 51.89 & 71.78 & 51.05 \\
\rowcolor[rgb]{0.928, 0.936, 0.997}
+ PRAgent & 71.65 & 73.22 & 73.45 & 60.73 & 70.96 & 35.84 & 96.09 & 93.46 & 74.81 & 68.65 & 56.38 & 91.41 & 72.22 \\
\midrule
\rowcolor[rgb]{0.997, 0.936, 0.928}
human-authored posts & 53.32 & 47.10 & 45.90 & 42.89 & 70.48 & 30.68 & - & - & 52.34 & 66.34 & 33.92 & - & - \\
\bottomrule
\end{tabular}%
}
\caption{The results on the \textcolor{purple}{PRBench}. For each model, we compare the performance of our \textbf{PRAgent} against the \textbf{Direct Prompt} baseline.}
\label{tab:pragent-full}
\end{table*}





