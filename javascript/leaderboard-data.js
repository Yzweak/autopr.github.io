// Auto-generated from files/data.tex
const prBenchCoreData = [
    {
        "model": "DeepSeek-R1-Distill-7B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "7B",
        "fidelity_att": 43.25,
        "factual_score": 21.45,
        "hook": 33.07,
        "logical_attr": 45.04,
        "visual_attr": null,
        "cta": 15.34,
        "prof_pref": 37.70,
        "broad_pref": 43.25,
        "context_rel": 31.28,
        "vis_txt_integ": null,
        "hashtag": 17.13,
        "plat_pref": 23.02,
        "avg": 31.05
    },
    {
        "model": "DeepSeek-R1-Distill-7B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "7B",
        "fidelity_att": 55.60,
        "factual_score": 36.43,
        "hook": 68.10,
        "logical_attr": 71.58,
        "visual_attr": 62.89,
        "cta": 34.96,
        "prof_pref": 72.27,
        "broad_pref": 88.67,
        "context_rel": 66.89,
        "vis_txt_integ": 66.47,
        "hashtag": 52.64,
        "plat_pref": 81.64,
        "avg": 63.18
    },
    {
        "model": "Qwen2.5-VL-7B-Ins",
        "method": "Direct Prompt",
        "model_size": "7B",
        "fidelity_att": 49.15,
        "factual_score": 39.17,
        "hook": 62.83,
        "logical_attr": 46.60,
        "visual_attr": null,
        "cta": 39.19,
        "prof_pref": 34.77,
        "broad_pref": 58.59,
        "context_rel": 55.86,
        "vis_txt_integ": null,
        "hashtag": 40.46,
        "plat_pref": 60.16,
        "avg": 48.68
    },
    {
        "model": "Qwen2.5-VL-7B-Ins",
        "method": "PRAgent",
        "model_size": "7B",
        "fidelity_att": 62.17,
        "factual_score": 57.89,
        "hook": 62.57,
        "logical_attr": 58.33,
        "visual_attr": 59.32,
        "cta": 15.62,
        "prof_pref": 66.41,
        "broad_pref": 74.61,
        "context_rel": 57.40,
        "vis_txt_integ": 60.61,
        "hashtag": 50.26,
        "plat_pref": 70.31,
        "avg": 57.96
    },
    {
        "model": "InternVL3-8B",
        "method": "Direct Prompt",
        "model_size": "8B",
        "fidelity_att": 52.67,
        "factual_score": 48.55,
        "hook": 72.01,
        "logical_attr": 53.09,
        "visual_attr": null,
        "cta": 50,
        "prof_pref": 63.67,
        "broad_pref": 81.64,
        "context_rel": 66.34,
        "vis_txt_integ": null,
        "hashtag": 56.58,
        "plat_pref": 85.16,
        "avg": 62.97
    },
    {
        "model": "InternVL3-8B",
        "method": "PRAgent",
        "model_size": "8B",
        "fidelity_att": 64.06,
        "factual_score": 52.50,
        "hook": 73.37,
        "logical_attr": 57.62,
        "visual_attr": 68.75,
        "cta": 44.27,
        "prof_pref": 60.55,
        "broad_pref": 88.67,
        "context_rel": 74.93,
        "vis_txt_integ": 66.24,
        "hashtag": 50.68,
        "plat_pref": 80.86,
        "avg": 65.21
    },
    {
        "model": "Qwen3-8B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "8B",
        "fidelity_att": 51.76,
        "factual_score": 45.09,
        "hook": 73.83,
        "logical_attr": 51.69,
        "visual_attr": null,
        "cta": 44.27,
        "prof_pref": 62.50,
        "broad_pref": 78.91,
        "context_rel": 72.10,
        "vis_txt_integ": null,
        "hashtag": 61.46,
        "plat_pref": 91.41,
        "avg": 63.30
    },
    {
        "model": "Qwen3-8B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "8B",
        "fidelity_att": 69.01,
        "factual_score": 62.11,
        "hook": 75,
        "logical_attr": 83.53,
        "visual_attr": 70.57,
        "cta": 45.44,
        "prof_pref": 96.09,
        "broad_pref": 98.44,
        "context_rel": 86.33,
        "vis_txt_integ": 71.78,
        "hashtag": 62.11,
        "plat_pref": 98.44,
        "avg": 76.57
    },
    {
        "model": "DeepSeek-R1-Distill-14B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 51.37,
        "factual_score": 43.57,
        "hook": 69.14,
        "logical_attr": 54.92,
        "visual_attr": null,
        "cta": 29.56,
        "prof_pref": 60.16,
        "broad_pref": 75.78,
        "context_rel": 64.23,
        "vis_txt_integ": null,
        "hashtag": 50.13,
        "plat_pref": 81.64,
        "avg": 58.05
    },
    {
        "model": "DeepSeek-R1-Distill-14B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 66.60,
        "factual_score": 57.21,
        "hook": 74.80,
        "logical_attr": 77.64,
        "visual_attr": 73.31,
        "cta": 38.48,
        "prof_pref": 91.80,
        "broad_pref": 98.83,
        "context_rel": 80.37,
        "vis_txt_integ": 72.66,
        "hashtag": 54.95,
        "plat_pref": 99.22,
        "avg": 73.82
    },
    {
        "model": "InternVL3-14B",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 52.41,
        "factual_score": 49.12,
        "hook": 71.29,
        "logical_attr": 54.52,
        "visual_attr": null,
        "cta": 55.66,
        "prof_pref": 56.64,
        "broad_pref": 80.86,
        "context_rel": 68.52,
        "vis_txt_integ": null,
        "hashtag": 57.06,
        "plat_pref": 88.67,
        "avg": 63.48
    },
    {
        "model": "InternVL3-14B",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 64.78,
        "factual_score": 55.91,
        "hook": 75.26,
        "logical_attr": 67.06,
        "visual_attr": 73.05,
        "cta": 52.80,
        "prof_pref": 73.05,
        "broad_pref": 92.19,
        "context_rel": 80.79,
        "vis_txt_integ": 71.55,
        "hashtag": 53.22,
        "plat_pref": 87.89,
        "avg": 70.63
    },
    {
        "model": "Qwen3-14B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 50.91,
        "factual_score": 47.44,
        "hook": 74.80,
        "logical_attr": 56.25,
        "visual_attr": null,
        "cta": 38.15,
        "prof_pref": 69.53,
        "broad_pref": 82.03,
        "context_rel": 72.30,
        "vis_txt_integ": null,
        "hashtag": 65.23,
        "plat_pref": 95.31,
        "avg": 65.20
    },
    {
        "model": "Qwen3-14B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 70.31,
        "factual_score": 67.70,
        "hook": 75,
        "logical_attr": 81.38,
        "visual_attr": 72.85,
        "cta": 35.35,
        "prof_pref": 97.66,
        "broad_pref": 99.61,
        "context_rel": 86.88,
        "vis_txt_integ": 74.38,
        "hashtag": 61.33,
        "plat_pref": 97.27,
        "avg": 76.64
    },
    {
        "model": "GPT-OSS-20B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "20B",
        "fidelity_att": 52.30,
        "factual_score": 56.11,
        "hook": 69.34,
        "logical_attr": 40.62,
        "visual_attr": null,
        "cta": 44.21,
        "prof_pref": 73.44,
        "broad_pref": 74.22,
        "context_rel": 71.52,
        "vis_txt_integ": null,
        "hashtag": 54.88,
        "plat_pref": 90.62,
        "avg": 62.73
    },
    {
        "model": "GPT-OSS-20B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "20B",
        "fidelity_att": 70.12,
        "factual_score": 75.28,
        "hook": 75,
        "logical_attr": 64.84,
        "visual_attr": 72.46,
        "cta": 47.33,
        "prof_pref": 99.22,
        "broad_pref": 98.05,
        "context_rel": 83.59,
        "vis_txt_integ": 73.63,
        "hashtag": 62.76,
        "plat_pref": 99.22,
        "avg": 76.79
    },
    {
        "model": "Qwen3-30B-A3B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "30B",
        "fidelity_att": 51.11,
        "factual_score": 43.03,
        "hook": 71.68,
        "logical_attr": 51.69,
        "visual_attr": null,
        "cta": 35.22,
        "prof_pref": 47.66,
        "broad_pref": 74.61,
        "context_rel": 67.84,
        "vis_txt_integ": null,
        "hashtag": 60.16,
        "plat_pref": 83.59,
        "avg": 58.66
    },
    {
        "model": "Qwen3-30B-A3B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "30B",
        "fidelity_att": 69.79,
        "factual_score": 56.45,
        "hook": 75,
        "logical_attr": 79.98,
        "visual_attr": 72.01,
        "cta": 30.01,
        "prof_pref": 98.44,
        "broad_pref": 98.44,
        "context_rel": 85.61,
        "vis_txt_integ": 72.36,
        "hashtag": 66.54,
        "plat_pref": 98.44,
        "avg": 75.26
    },
    {
        "model": "DeepSeek-R1-Distill-32B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 50,
        "factual_score": 42.49,
        "hook": 68.03,
        "logical_attr": 55.66,
        "visual_attr": null,
        "cta": 35.61,
        "prof_pref": 51.95,
        "broad_pref": 77.73,
        "context_rel": 67.25,
        "vis_txt_integ": null,
        "hashtag": 50.46,
        "plat_pref": 85.16,
        "avg": 58.43
    },
    {
        "model": "DeepSeek-R1-Distill-32B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 65.94,
        "factual_score": 55.82,
        "hook": 72.38,
        "logical_attr": 80.22,
        "visual_attr": 69.38,
        "cta": 37.80,
        "prof_pref": 92.91,
        "broad_pref": 96.06,
        "context_rel": 79.63,
        "vis_txt_integ": 70.51,
        "hashtag": 47.77,
        "plat_pref": 92.52,
        "avg": 71.74
    },
    {
        "model": "Qwen2.5-VL-32B-Ins",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 57.55,
        "factual_score": 59.87,
        "hook": 70.90,
        "logical_attr": 70.15,
        "visual_attr": null,
        "cta": 58.92,
        "prof_pref": 88.67,
        "broad_pref": 87.50,
        "context_rel": 67.68,
        "vis_txt_integ": null,
        "hashtag": 53.32,
        "plat_pref": 91.02,
        "avg": 70.56
    },
    {
        "model": "Qwen2.5-VL-32B-Ins",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 72.85,
        "factual_score": 72.49,
        "hook": 74.80,
        "logical_attr": 82.03,
        "visual_attr": 75.33,
        "cta": 51.69,
        "prof_pref": 98.05,
        "broad_pref": 100,
        "context_rel": 83.82,
        "vis_txt_integ": 75.03,
        "hashtag": 61.65,
        "plat_pref": 96.48,
        "avg": 78.69
    },
    {
        "model": "Qwen3-32B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 52.73,
        "factual_score": 52.56,
        "hook": 72.98,
        "logical_attr": 54.04,
        "visual_attr": null,
        "cta": 47.27,
        "prof_pref": 79.30,
        "broad_pref": 80.08,
        "context_rel": 70.41,
        "vis_txt_integ": null,
        "hashtag": 61.98,
        "plat_pref": 92.97,
        "avg": 66.43
    },
    {
        "model": "Qwen3-32B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 70.31,
        "factual_score": 64.94,
        "hook": 75,
        "logical_attr": 83.72,
        "visual_attr": 74.61,
        "cta": 42.32,
        "prof_pref": 99.22,
        "broad_pref": 100,
        "context_rel": 86.91,
        "vis_txt_integ": 75.39,
        "hashtag": 60.71,
        "plat_pref": 99.22,
        "avg": 77.70
    },
    {
        "model": "InternVL3-38B",
        "method": "Direct Prompt",
        "model_size": "38B",
        "fidelity_att": 51.37,
        "factual_score": 43.82,
        "hook": 71.16,
        "logical_attr": 53.91,
        "visual_attr": null,
        "cta": 50.07,
        "prof_pref": 44.14,
        "broad_pref": 77.73,
        "context_rel": 68.46,
        "vis_txt_integ": null,
        "hashtag": 50.81,
        "plat_pref": 85.94,
        "avg": 59.74
    },
    {
        "model": "InternVL3-38B",
        "method": "PRAgent",
        "model_size": "38B",
        "fidelity_att": 65.69,
        "factual_score": 56.84,
        "hook": 75,
        "logical_attr": 72.10,
        "visual_attr": 74.02,
        "cta": 47.92,
        "prof_pref": 85.55,
        "broad_pref": 96.88,
        "context_rel": 83.66,
        "vis_txt_integ": 74.28,
        "hashtag": 50.91,
        "plat_pref": 96.09,
        "avg": 73.25
    },
    {
        "model": "Qwen-2.5-VL-72B-Ins",
        "method": "Direct Prompt",
        "model_size": "72B",
        "fidelity_att": 52.08,
        "factual_score": 44.43,
        "hook": 74.41,
        "logical_attr": 62.83,
        "visual_attr": null,
        "cta": 57.81,
        "prof_pref": 58.20,
        "broad_pref": 83.98,
        "context_rel": 74.67,
        "vis_txt_integ": null,
        "hashtag": 55.53,
        "plat_pref": 93.75,
        "avg": 65.77
    },
    {
        "model": "Qwen-2.5-VL-72B-Ins",
        "method": "PRAgent",
        "model_size": "72B",
        "fidelity_att": 70.05,
        "factual_score": 60.75,
        "hook": 75,
        "logical_attr": 75.68,
        "visual_attr": 74.93,
        "cta": 30.99,
        "prof_pref": 89.45,
        "broad_pref": 97.27,
        "context_rel": 81.32,
        "vis_txt_integ": 74.22,
        "hashtag": 41.60,
        "plat_pref": 96.48,
        "avg": 72.31
    },
    {
        "model": "GPT-OSS-120B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "120B",
        "fidelity_att": 52.67,
        "factual_score": 59.85,
        "hook": 68.55,
        "logical_attr": 41.02,
        "visual_attr": null,
        "cta": 43.29,
        "prof_pref": 76.17,
        "broad_pref": 78.91,
        "context_rel": 73.86,
        "vis_txt_integ": null,
        "hashtag": 67.45,
        "plat_pref": 92.19,
        "avg": 65.40
    },
    {
        "model": "GPT-OSS-120B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "120B",
        "fidelity_att": 69.34,
        "factual_score": 79.42,
        "hook": 75,
        "logical_attr": 66.37,
        "visual_attr": 72.79,
        "cta": 46.94,
        "prof_pref": 100,
        "broad_pref": 98.05,
        "context_rel": 81.74,
        "vis_txt_integ": 74.12,
        "hashtag": 60.61,
        "plat_pref": 100,
        "avg": 77.03
    },
    {
        "model": "Qwen3-235B-A22B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "235B",
        "fidelity_att": 55.34,
        "factual_score": 54.28,
        "hook": 74.22,
        "logical_attr": 57.29,
        "visual_attr": null,
        "cta": 51.82,
        "prof_pref": 80.47,
        "broad_pref": 84.38,
        "context_rel": 74.41,
        "vis_txt_integ": null,
        "hashtag": 69.99,
        "plat_pref": 96.09,
        "avg": 69.83
    },
    {
        "model": "Qwen3-235B-A22B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "235B",
        "fidelity_att": 66.80,
        "factual_score": 66.92,
        "hook": 75.33,
        "logical_attr": 83.69,
        "visual_attr": 74.87,
        "cta": 42.58,
        "prof_pref": 97.66,
        "broad_pref": 100,
        "context_rel": 87.17,
        "vis_txt_integ": 75.10,
        "hashtag": 61.13,
        "plat_pref": 97.66,
        "avg": 77.41
    },
    {
        "model": "Gemini-2.5-Flash",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 55.01,
        "factual_score": 45.10,
        "hook": 74.48,
        "logical_attr": 61.78,
        "visual_attr": null,
        "cta": 48.96,
        "prof_pref": 39.06,
        "broad_pref": 83.98,
        "context_rel": 80.47,
        "vis_txt_integ": null,
        "hashtag": 61.20,
        "plat_pref": 93.75,
        "avg": 64.38
    },
    {
        "model": "Gemini-2.5-Flash",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 70.83,
        "factual_score": 70.01,
        "hook": 75,
        "logical_attr": 82.32,
        "visual_attr": 74.48,
        "cta": 46.81,
        "prof_pref": 97.27,
        "broad_pref": 98.83,
        "context_rel": 85.84,
        "vis_txt_integ": 74.80,
        "hashtag": 57.42,
        "plat_pref": 98.05,
        "avg": 77.64
    },
    {
        "model": "Gemini-2.5-Pro<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 56.77,
        "factual_score": 47.44,
        "hook": 75,
        "logical_attr": 69.79,
        "visual_attr": null,
        "cta": 44.27,
        "prof_pref": 46.88,
        "broad_pref": 88.67,
        "context_rel": 81.41,
        "vis_txt_integ": null,
        "hashtag": 59.57,
        "plat_pref": 94.92,
        "avg": 66.47
    },
    {
        "model": "Gemini-2.5-Pro<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 71.81,
        "factual_score": 63.14,
        "hook": 74.47,
        "logical_attr": 85.97,
        "visual_attr": 73.89,
        "cta": 45.44,
        "prof_pref": 97.27,
        "broad_pref": 99.22,
        "context_rel": 86.04,
        "vis_txt_integ": 74.58,
        "hashtag": 58.40,
        "plat_pref": 98.05,
        "avg": 77.36
    },
    {
        "model": "GPT-4.1",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 51,
        "factual_score": 38.75,
        "hook": 74,
        "logical_attr": 56,
        "visual_attr": null,
        "cta": 45.67,
        "prof_pref": 50,
        "broad_pref": 70,
        "context_rel": 69,
        "vis_txt_integ": null,
        "hashtag": 52.33,
        "plat_pref": 84,
        "avg": 59.08
    },
    {
        "model": "GPT-4.1",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 70.67,
        "factual_score": 77.19,
        "hook": 75.50,
        "logical_attr": 83,
        "visual_attr": 75.33,
        "cta": 46.67,
        "prof_pref": 100,
        "broad_pref": 100,
        "context_rel": 86,
        "vis_txt_integ": 75.33,
        "hashtag": 60.67,
        "plat_pref": 98,
        "avg": 79.03
    },
    {
        "model": "GPT-4o",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 50.52,
        "factual_score": 30.73,
        "hook": 72.93,
        "logical_attr": 48.06,
        "visual_attr": null,
        "cta": 42.84,
        "prof_pref": 28.12,
        "broad_pref": 64.45,
        "context_rel": 60.58,
        "vis_txt_integ": null,
        "hashtag": 53.26,
        "plat_pref": 55.08,
        "avg": 50.66
    },
    {
        "model": "GPT-4o",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 66.99,
        "factual_score": 46.58,
        "hook": 75,
        "logical_attr": 75.07,
        "visual_attr": 74.80,
        "cta": 47.59,
        "prof_pref": 75.78,
        "broad_pref": 98.05,
        "context_rel": 81.87,
        "vis_txt_integ": 73.93,
        "hashtag": 52.15,
        "plat_pref": 97.66,
        "avg": 72.12
    },
    {
        "model": "GPT-5<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 52.73,
        "factual_score": 50.19,
        "hook": 74.15,
        "logical_attr": 45.15,
        "visual_attr": null,
        "cta": 37.70,
        "prof_pref": 74.61,
        "broad_pref": 83.20,
        "context_rel": 75.03,
        "vis_txt_integ": null,
        "hashtag": 52.02,
        "plat_pref": 94.92,
        "avg": 63.97
    },
    {
        "model": "GPT-5<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 68.16,
        "factual_score": 73.30,
        "hook": 75,
        "logical_attr": 80.40,
        "visual_attr": 75.20,
        "cta": 34.70,
        "prof_pref": 99.22,
        "broad_pref": 100,
        "context_rel": 86.65,
        "vis_txt_integ": 75.33,
        "hashtag": 53.06,
        "plat_pref": 98.44,
        "avg": 76.62
    },
    {
        "model": "GPT-5-mini<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 51.37,
        "factual_score": 61.80,
        "hook": 55.27,
        "logical_attr": 38.74,
        "visual_attr": null,
        "cta": 31.90,
        "prof_pref": 65.23,
        "broad_pref": 61.72,
        "context_rel": 57.71,
        "vis_txt_integ": null,
        "hashtag": 40.30,
        "plat_pref": 79.69,
        "avg": 54.37
    },
    {
        "model": "GPT-5-mini<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 72.33,
        "factual_score": 83.61,
        "hook": 74.61,
        "logical_attr": 68.07,
        "visual_attr": 74.61,
        "cta": 43.49,
        "prof_pref": 99.22,
        "broad_pref": 99.61,
        "context_rel": 81.97,
        "vis_txt_integ": 73.83,
        "hashtag": 52.60,
        "plat_pref": 96.48,
        "avg": 76.70
    },
    {
        "model": "GPT-5-nano<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 49.80,
        "factual_score": 57.91,
        "hook": 51.56,
        "logical_attr": 37.34,
        "visual_attr": null,
        "cta": 34.31,
        "prof_pref": 58.59,
        "broad_pref": 51.95,
        "context_rel": 52.51,
        "vis_txt_integ": null,
        "hashtag": 49.28,
        "plat_pref": 73.05,
        "avg": 51.63
    },
    {
        "model": "GPT-5-nano<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 71.29,
        "factual_score": 70.80,
        "hook": 72.53,
        "logical_attr": 61.75,
        "visual_attr": 69.53,
        "cta": 34.70,
        "prof_pref": 94.92,
        "broad_pref": 94.14,
        "context_rel": 73.63,
        "vis_txt_integ": 67.81,
        "hashtag": 55.47,
        "plat_pref": 94.53,
        "avg": 71.76
    }
];

const prBenchFullData = [
    {
        "model": "DeepSeek-R1-Distill-7B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "7B",
        "fidelity_att": 43.27,
        "factual_score": 20.39,
        "hook": 36.53,
        "logical_attr": 48.30,
        "visual_attr": null,
        "cta": 18.87,
        "prof_pref": 40.16,
        "broad_pref": 45.57,
        "context_rel": 33.52,
        "vis_txt_integ": null,
        "hashtag": 20.28,
        "plat_pref": 26.38,
        "avg": 33.33
    },
    {
        "model": "DeepSeek-R1-Distill-7B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "7B",
        "fidelity_att": 55.75,
        "factual_score": 32.61,
        "hook": 67.94,
        "logical_attr": 70.33,
        "visual_attr": 63.96,
        "cta": 33.97,
        "prof_pref": 65.62,
        "broad_pref": 87.40,
        "context_rel": 65.81,
        "vis_txt_integ": 66.49,
        "hashtag": 48.62,
        "plat_pref": 81.45,
        "avg": 61.66
    },
    {
        "model": "Qwen-2.5-VL-7B-Instruct",
        "method": "Direct Prompt",
        "model_size": "7B",
        "fidelity_att": 48.32,
        "factual_score": 36.52,
        "hook": 61.98,
        "logical_attr": 46.98,
        "visual_attr": null,
        "cta": 38.82,
        "prof_pref": 35.35,
        "broad_pref": 56.45,
        "context_rel": 55.86,
        "vis_txt_integ": null,
        "hashtag": 40.72,
        "plat_pref": 58.01,
        "avg": 47.90
    },
    {
        "model": "Qwen-2.5-VL-7B-Instruct",
        "method": "PRAgent",
        "model_size": "7B",
        "fidelity_att": 61.75,
        "factual_score": 55.69,
        "hook": 61.76,
        "logical_attr": 58.66,
        "visual_attr": 60.24,
        "cta": 16.06,
        "prof_pref": 67.97,
        "broad_pref": 75,
        "context_rel": 57.43,
        "vis_txt_integ": 61.64,
        "hashtag": 49.65,
        "plat_pref": 67.09,
        "avg": 57.74
    },
    {
        "model": "InternVL3-8B",
        "method": "Direct Prompt",
        "model_size": "8B",
        "fidelity_att": 51.71,
        "factual_score": 44.89,
        "hook": 70.96,
        "logical_attr": 53,
        "visual_attr": null,
        "cta": 50,
        "prof_pref": 58.59,
        "broad_pref": 77.83,
        "context_rel": 66.76,
        "vis_txt_integ": null,
        "hashtag": 56.28,
        "plat_pref": 83.98,
        "avg": 61.40
    },
    {
        "model": "InternVL3-8B",
        "method": "PRAgent",
        "model_size": "8B",
        "fidelity_att": 64.08,
        "factual_score": 51.06,
        "hook": 73.47,
        "logical_attr": 58.49,
        "visual_attr": 69.90,
        "cta": 45.85,
        "prof_pref": 63.28,
        "broad_pref": 88.77,
        "context_rel": 75.49,
        "vis_txt_integ": 67.33,
        "hashtag": 51.44,
        "plat_pref": 81.93,
        "avg": 65.92
    },
    {
        "model": "Qwen3-8B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "8B",
        "fidelity_att": 51.16,
        "factual_score": 42.69,
        "hook": 73.26,
        "logical_attr": 52.51,
        "visual_attr": null,
        "cta": 41.24,
        "prof_pref": 60.64,
        "broad_pref": 76.17,
        "context_rel": 71.40,
        "vis_txt_integ": null,
        "hashtag": 60.61,
        "plat_pref": 89.65,
        "avg": 61.93
    },
    {
        "model": "Qwen3-8B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "8B",
        "fidelity_att": 67.95,
        "factual_score": 58.96,
        "hook": 75,
        "logical_attr": 83.53,
        "visual_attr": 71.97,
        "cta": 45.30,
        "prof_pref": 97.56,
        "broad_pref": 99.22,
        "context_rel": 86.86,
        "vis_txt_integ": 72.74,
        "hashtag": 61.50,
        "plat_pref": 97.95,
        "avg": 76.54
    },
    {
        "model": "DeepSeek-R1-Distill-14B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 50.67,
        "factual_score": 41.73,
        "hook": 69.47,
        "logical_attr": 55.39,
        "visual_attr": null,
        "cta": 30.72,
        "prof_pref": 57.44,
        "broad_pref": 71.33,
        "context_rel": 64.34,
        "vis_txt_integ": null,
        "hashtag": 49.41,
        "plat_pref": 81.02,
        "avg": 57.15
    },
    {
        "model": "DeepSeek-R1-Distill-14B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 65.61,
        "factual_score": 53.86,
        "hook": 74.62,
        "logical_attr": 77.94,
        "visual_attr": 71.94,
        "cta": 39.29,
        "prof_pref": 91.31,
        "broad_pref": 98.63,
        "context_rel": 80.53,
        "vis_txt_integ": 71.91,
        "hashtag": 53.32,
        "plat_pref": 97.85,
        "avg": 73.07
    },
    {
        "model": "InternVL3-14B",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 51.63,
        "factual_score": 46.51,
        "hook": 71.06,
        "logical_attr": 54.17,
        "visual_attr": null,
        "cta": 54.82,
        "prof_pref": 53.42,
        "broad_pref": 76.17,
        "context_rel": 68.76,
        "vis_txt_integ": null,
        "hashtag": 56.32,
        "plat_pref": 85.84,
        "avg": 61.87
    },
    {
        "model": "InternVL3-14B",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 64.56,
        "factual_score": 54.34,
        "hook": 75.62,
        "logical_attr": 68.08,
        "visual_attr": 73.18,
        "cta": 52.13,
        "prof_pref": 74.61,
        "broad_pref": 94.24,
        "context_rel": 81.57,
        "vis_txt_integ": 71.54,
        "hashtag": 54.41,
        "plat_pref": 90.53,
        "avg": 71.23
    },
    {
        "model": "Qwen3-14B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "14B",
        "fidelity_att": 51.12,
        "factual_score": 46.33,
        "hook": 73.73,
        "logical_attr": 56.45,
        "visual_attr": null,
        "cta": 39.62,
        "prof_pref": 68.46,
        "broad_pref": 80.57,
        "context_rel": 72.34,
        "vis_txt_integ": null,
        "hashtag": 64.78,
        "plat_pref": 92.09,
        "avg": 64.55
    },
    {
        "model": "Qwen3-14B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "14B",
        "fidelity_att": 69.58,
        "factual_score": 65.18,
        "hook": 75,
        "logical_attr": 82.18,
        "visual_attr": 73.88,
        "cta": 34.88,
        "prof_pref": 98.93,
        "broad_pref": 99.71,
        "context_rel": 86.83,
        "vis_txt_integ": 74.59,
        "hashtag": 60.90,
        "plat_pref": 98.05,
        "avg": 76.64
    },
    {
        "model": "GPT-oss-20B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "20B",
        "fidelity_att": 51.71,
        "factual_score": 54.89,
        "hook": 69.97,
        "logical_attr": 41.63,
        "visual_attr": null,
        "cta": 44.14,
        "prof_pref": 71.48,
        "broad_pref": 72.27,
        "context_rel": 71.77,
        "vis_txt_integ": null,
        "hashtag": 54.51,
        "plat_pref": 90.92,
        "avg": 62.33
    },
    {
        "model": "GPT-oss-20B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "20B",
        "fidelity_att": 69.74,
        "factual_score": 73.07,
        "hook": 74.85,
        "logical_attr": 64.97,
        "visual_attr": 73.04,
        "cta": 49.43,
        "prof_pref": 98.44,
        "broad_pref": 97.46,
        "context_rel": 83.47,
        "vis_txt_integ": 73.92,
        "hashtag": 62.24,
        "plat_pref": 97.75,
        "avg": 76.53
    },
    {
        "model": "Qwen3-30B-A3B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "30B",
        "fidelity_att": 51.14,
        "factual_score": 40.76,
        "hook": 71.08,
        "logical_attr": 51.68,
        "visual_attr": null,
        "cta": 35.63,
        "prof_pref": 48.44,
        "broad_pref": 68.46,
        "context_rel": 67.43,
        "vis_txt_integ": null,
        "hashtag": 60.09,
        "plat_pref": 81.74,
        "avg": 57.64
    },
    {
        "model": "Qwen3-30B-A3B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "30B",
        "fidelity_att": 69.40,
        "factual_score": 54.95,
        "hook": 74.85,
        "logical_attr": 80.69,
        "visual_attr": 72.27,
        "cta": 30.08,
        "prof_pref": 96.68,
        "broad_pref": 98.24,
        "context_rel": 85.45,
        "vis_txt_integ": 73.32,
        "hashtag": 65.89,
        "plat_pref": 97.56,
        "avg": 74.95
    },
    {
        "model": "DeepSeek-R1-Distill-32B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 50.52,
        "factual_score": 41.79,
        "hook": 69.16,
        "logical_attr": 57.20,
        "visual_attr": null,
        "cta": 36.65,
        "prof_pref": 56.64,
        "broad_pref": 73.63,
        "context_rel": 67.16,
        "vis_txt_integ": null,
        "hashtag": 49.63,
        "plat_pref": 85.16,
        "avg": 58.75
    },
    {
        "model": "DeepSeek-R1-Distill-32B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 65.85,
        "factual_score": 54.88,
        "hook": 74.10,
        "logical_attr": 81.44,
        "visual_attr": 70.65,
        "cta": 39.53,
        "prof_pref": 92.86,
        "broad_pref": 97.26,
        "context_rel": 81.25,
        "vis_txt_integ": 71.58,
        "hashtag": 49.12,
        "plat_pref": 93.64,
        "avg": 72.68
    },
    {
        "model": "Qwen-2.5-VL-32B-Instruct",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 56.90,
        "factual_score": 55.88,
        "hook": 69.71,
        "logical_attr": 69.78,
        "visual_attr": null,
        "cta": 56.20,
        "prof_pref": 87.01,
        "broad_pref": 85.84,
        "context_rel": 66.18,
        "vis_txt_integ": null,
        "hashtag": 52.78,
        "plat_pref": 88.57,
        "avg": 68.88
    },
    {
        "model": "Qwen-2.5-VL-32B-Instruct",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 71.56,
        "factual_score": 69.96,
        "hook": 74.95,
        "logical_attr": 82.75,
        "visual_attr": 75.15,
        "cta": 53.47,
        "prof_pref": 98.83,
        "broad_pref": 99.71,
        "context_rel": 83.46,
        "vis_txt_integ": 75.01,
        "hashtag": 61.90,
        "plat_pref": 97.16,
        "avg": 78.66
    },
    {
        "model": "Qwen3-32B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "32B",
        "fidelity_att": 52.25,
        "factual_score": 49.68,
        "hook": 72.51,
        "logical_attr": 53.52,
        "visual_attr": null,
        "cta": 47.97,
        "prof_pref": 78.22,
        "broad_pref": 77.93,
        "context_rel": 69.60,
        "vis_txt_integ": null,
        "hashtag": 61.21,
        "plat_pref": 90.53,
        "avg": 65.34
    },
    {
        "model": "Qwen3-32B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "32B",
        "fidelity_att": 71.14,
        "factual_score": 64.53,
        "hook": 75,
        "logical_attr": 83,
        "visual_attr": 74.82,
        "cta": 42.74,
        "prof_pref": 98.83,
        "broad_pref": 99.71,
        "context_rel": 86.69,
        "vis_txt_integ": 75.12,
        "hashtag": 60.59,
        "plat_pref": 98.24,
        "avg": 77.53
    },
    {
        "model": "InternVL3-38B",
        "method": "Direct Prompt",
        "model_size": "38B",
        "fidelity_att": 50.93,
        "factual_score": 41.47,
        "hook": 70.20,
        "logical_attr": 53.52,
        "visual_attr": null,
        "cta": 50.07,
        "prof_pref": 48.05,
        "broad_pref": 74.22,
        "context_rel": 67.44,
        "vis_txt_integ": null,
        "hashtag": 51.11,
        "plat_pref": 82.91,
        "avg": 58.99
    },
    {
        "model": "InternVL3-38B",
        "method": "PRAgent",
        "model_size": "38B",
        "fidelity_att": 66.52,
        "factual_score": 53.23,
        "hook": 74.56,
        "logical_attr": 72.87,
        "visual_attr": 74.10,
        "cta": 48.47,
        "prof_pref": 84.47,
        "broad_pref": 96.97,
        "context_rel": 83.11,
        "vis_txt_integ": 73.58,
        "hashtag": 50.75,
        "plat_pref": 96.97,
        "avg": 72.97
    },
    {
        "model": "Qwen-2.5-VL-72B-Instruct",
        "method": "Direct Prompt",
        "model_size": "72B",
        "fidelity_att": 52.78,
        "factual_score": 42.61,
        "hook": 74.10,
        "logical_attr": 62.51,
        "visual_attr": null,
        "cta": 57.10,
        "prof_pref": 56.05,
        "broad_pref": 82.52,
        "context_rel": 74.20,
        "vis_txt_integ": null,
        "hashtag": 55.03,
        "plat_pref": 91.89,
        "avg": 64.88
    },
    {
        "model": "Qwen-2.5-VL-72B-Instruct",
        "method": "PRAgent",
        "model_size": "72B",
        "fidelity_att": 69.43,
        "factual_score": 58.45,
        "hook": 74.71,
        "logical_attr": 75.07,
        "visual_attr": 74.79,
        "cta": 29.70,
        "prof_pref": 88.96,
        "broad_pref": 97.56,
        "context_rel": 80.37,
        "vis_txt_integ": 73.93,
        "hashtag": 40.97,
        "plat_pref": 96.29,
        "avg": 71.69
    },
    {
        "model": "GPT-oss-120B<sup>R,T</sup>",
        "method": "Direct Prompt",
        "model_size": "120B",
        "fidelity_att": 52.64,
        "factual_score": 58.45,
        "hook": 69.34,
        "logical_attr": 41.79,
        "visual_attr": null,
        "cta": 41.54,
        "prof_pref": 74.32,
        "broad_pref": 72.46,
        "context_rel": 72.59,
        "vis_txt_integ": null,
        "hashtag": 65.32,
        "plat_pref": 91.99,
        "avg": 64.04
    },
    {
        "model": "GPT-oss-120B<sup>R,T</sup>",
        "method": "PRAgent",
        "model_size": "120B",
        "fidelity_att": 68.64,
        "factual_score": 77.15,
        "hook": 74.92,
        "logical_attr": 68.13,
        "visual_attr": 73.91,
        "cta": 47.71,
        "prof_pref": 99.41,
        "broad_pref": 98.34,
        "context_rel": 81.68,
        "vis_txt_integ": 74.53,
        "hashtag": 59.83,
        "plat_pref": 98.73,
        "avg": 76.91
    },
    {
        "model": "Qwen3-235B-A22B<sup>T</sup>",
        "method": "Direct Prompt",
        "model_size": "235B",
        "fidelity_att": 56.10,
        "factual_score": 51.28,
        "hook": 74.25,
        "logical_attr": 56.88,
        "visual_attr": null,
        "cta": 52.20,
        "prof_pref": 78.03,
        "broad_pref": 82.81,
        "context_rel": 74.49,
        "vis_txt_integ": null,
        "hashtag": 68.51,
        "plat_pref": 95.21,
        "avg": 68.98
    },
    {
        "model": "Qwen3-235B-A22B<sup>T</sup>",
        "method": "PRAgent",
        "model_size": "235B",
        "fidelity_att": 67.95,
        "factual_score": 66.96,
        "hook": 75.02,
        "logical_attr": 83.96,
        "visual_attr": 74.53,
        "cta": 44.25,
        "prof_pref": 98.63,
        "broad_pref": 99.61,
        "context_rel": 87.09,
        "vis_txt_integ": 75.11,
        "hashtag": 60.45,
        "plat_pref": 98.54,
        "avg": 77.68
    },
    {
        "model": "Gemini-2.5-Flash",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 54.29,
        "factual_score": 43.20,
        "hook": 74.41,
        "logical_attr": 62.07,
        "visual_attr": null,
        "cta": 47.05,
        "prof_pref": 38.38,
        "broad_pref": 79.98,
        "context_rel": 80.83,
        "vis_txt_integ": null,
        "hashtag": 61.47,
        "plat_pref": 91.80,
        "avg": 63.35
    },
    {
        "model": "Gemini-2.5-Flash",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 70.43,
        "factual_score": 67.97,
        "hook": 74.53,
        "logical_attr": 82.88,
        "visual_attr": 74.41,
        "cta": 46.61,
        "prof_pref": 97.46,
        "broad_pref": 98.73,
        "context_rel": 85.32,
        "vis_txt_integ": 74.64,
        "hashtag": 58.30,
        "plat_pref": 96.09,
        "avg": 77.28
    },
    {
        "model": "Gemini-2.5-Pro<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 57.05,
        "factual_score": 46.46,
        "hook": 75.29,
        "logical_attr": 69.70,
        "visual_attr": null,
        "cta": 45.49,
        "prof_pref": 46,
        "broad_pref": 86.82,
        "context_rel": 81.01,
        "vis_txt_integ": null,
        "hashtag": 59.86,
        "plat_pref": 93.26,
        "avg": 66.09
    },
    {
        "model": "Gemini-2.5-Pro<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 72.31,
        "factual_score": 62.22,
        "hook": 75.09,
        "logical_attr": 86.11,
        "visual_attr": 74.80,
        "cta": 47.35,
        "prof_pref": 98.93,
        "broad_pref": 99.80,
        "context_rel": 86.86,
        "vis_txt_integ": 75.08,
        "hashtag": 58.02,
        "plat_pref": 99.02,
        "avg": 77.97
    },
    {
        "model": "GPT-4.1",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 50.98,
        "factual_score": 37.77,
        "hook": 74.80,
        "logical_attr": 55.53,
        "visual_attr": null,
        "cta": 42.19,
        "prof_pref": 48.83,
        "broad_pref": 77.73,
        "context_rel": 73.01,
        "vis_txt_integ": null,
        "hashtag": 53.32,
        "plat_pref": 90.62,
        "avg": 60.48
    },
    {
        "model": "GPT-4.1",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 72.66,
        "factual_score": 71.42,
        "hook": 75.20,
        "logical_attr": 81.48,
        "visual_attr": 75.33,
        "cta": 47.27,
        "prof_pref": 98.05,
        "broad_pref": 99.22,
        "context_rel": 85.06,
        "vis_txt_integ": 75.56,
        "hashtag": 59.11,
        "plat_pref": 96.48,
        "avg": 78.07
    },
    {
        "model": "GPT-4o",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 49.72,
        "factual_score": 29.30,
        "hook": 72.21,
        "logical_attr": 47.54,
        "visual_attr": null,
        "cta": 40.97,
        "prof_pref": 30.86,
        "broad_pref": 59.77,
        "context_rel": 60.15,
        "vis_txt_integ": null,
        "hashtag": 52.41,
        "plat_pref": 54.10,
        "avg": 49.70
    },
    {
        "model": "GPT-4o",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 66.32,
        "factual_score": 45.94,
        "hook": 75,
        "logical_attr": 75.22,
        "visual_attr": 74.89,
        "cta": 49.07,
        "prof_pref": 77.93,
        "broad_pref": 98.24,
        "context_rel": 81.83,
        "vis_txt_integ": 74.17,
        "hashtag": 52.08,
        "plat_pref": 97.66,
        "avg": 72.36
    },
    {
        "model": "GPT-5<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 51.71,
        "factual_score": 47.84,
        "hook": 74.06,
        "logical_attr": 45.75,
        "visual_attr": null,
        "cta": 37.68,
        "prof_pref": 72.75,
        "broad_pref": 78.81,
        "context_rel": 75,
        "vis_txt_integ": null,
        "hashtag": 50.57,
        "plat_pref": 94.34,
        "avg": 62.85
    },
    {
        "model": "GPT-5<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 67.90,
        "factual_score": 72.07,
        "hook": 75,
        "logical_attr": 80.43,
        "visual_attr": 75.28,
        "cta": 34.82,
        "prof_pref": 98.73,
        "broad_pref": 99.51,
        "context_rel": 86.63,
        "vis_txt_integ": 75.66,
        "hashtag": 52.47,
        "plat_pref": 98.05,
        "avg": 76.38
    },
    {
        "model": "GPT-5-mini<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 50.83,
        "factual_score": 60.16,
        "hook": 55.73,
        "logical_attr": 39.41,
        "visual_attr": null,
        "cta": 33.30,
        "prof_pref": 64.55,
        "broad_pref": 59.08,
        "context_rel": 58.70,
        "vis_txt_integ": null,
        "hashtag": 39.44,
        "plat_pref": 79.20,
        "avg": 54.04
    },
    {
        "model": "GPT-5-mini<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 71.39,
        "factual_score": 82.35,
        "hook": 74.58,
        "logical_attr": 68.52,
        "visual_attr": 73.96,
        "cta": 42.85,
        "prof_pref": 99.22,
        "broad_pref": 98.24,
        "context_rel": 82.31,
        "vis_txt_integ": 73.58,
        "hashtag": 52.19,
        "plat_pref": 95.90,
        "avg": 76.26
    },
    {
        "model": "GPT-5-nano<sup>R</sup>",
        "method": "Direct Prompt",
        "model_size": null,
        "fidelity_att": 49.43,
        "factual_score": 56.91,
        "hook": 51.94,
        "logical_attr": 37.08,
        "visual_attr": null,
        "cta": 31.43,
        "prof_pref": 57.13,
        "broad_pref": 50.29,
        "context_rel": 52.65,
        "vis_txt_integ": null,
        "hashtag": 51.89,
        "plat_pref": 71.78,
        "avg": 51.05
    },
    {
        "model": "GPT-5-nano<sup>R</sup>",
        "method": "PRAgent",
        "model_size": null,
        "fidelity_att": 71.65,
        "factual_score": 73.22,
        "hook": 73.45,
        "logical_attr": 60.73,
        "visual_attr": 70.96,
        "cta": 35.84,
        "prof_pref": 96.09,
        "broad_pref": 93.46,
        "context_rel": 74.81,
        "vis_txt_integ": 68.65,
        "hashtag": 56.38,
        "plat_pref": 91.41,
        "avg": 72.22
    },
    {
        "model": "Human-authored posts",
        "method": "Human",
        "model_size": null,
        "fidelity_att": 53.32,
        "factual_score": 47.10,
        "hook": 45.90,
        "logical_attr": 42.89,
        "visual_attr": 70.48,
        "cta": 30.68,
        "prof_pref": null,
        "broad_pref": null,
        "context_rel": 52.34,
        "vis_txt_integ": 66.34,
        "hashtag": 33.92,
        "plat_pref": null,
        "avg": null
    }
];

/**
 * Timeline entries are intentionally lightweight so new milestones can be added quickly.
 * Each item may specify label/title/summary plus per-split SOTA numbers at that time.
 */
const autoPrTimeline = [
    {
        label: "Update 01",
        date: "2025-09-30",
        title: "Direct Prompt SOTA established",
        summary: "Baseline direct prompt submissions set the reference point for both splits.",
        coreAvg: 70.56,
        coreModel: "Qwen2.5-VL-32B-Ins",
        fullAvg: 68.98,
        fullModel: "Qwen3-235B-A22B"
    },
    {
        label: "Update 02",
        date: "2025-10-8",
        title: "PRAgent SOTA established",
        summary: "Best PRAgent pipelines surpass the direct baseline on both PRBench splits.",
        coreAvg: 79.03,
        coreModel: "PRAgent · GPT-4.1",
        fullAvg: 78.66,
        fullModel: "PRAgent · Qwen-2.5-VL-32B-Ins"
    }
];

if (typeof window !== "undefined") {
    window.autoPrTimeline = autoPrTimeline;
}
